{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7. Encrypted Deep Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0QqB2WBPsbV",
        "colab_type": "text"
      },
      "source": [
        "## **7. Encrypted Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho5uuV_XdMn1",
        "colab_type": "text"
      },
      "source": [
        "### **Encrypted computation in PySyft**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnHHBA_EO7es",
        "colab_type": "code",
        "outputId": "65a192ee-e2b8-490a-ab9a-f896de115266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import syft as sy\n",
        "import torch as th\n",
        "hook = sy.TorchHook(th)\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 15:24:14.065461 139722714326912 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0701 15:24:14.090709 139722714326912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcroQMFCxbHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJjspdtRxv7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M4yqOVNx9Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoNHB4YdyM4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH4fji9_ytJh",
        "colab_type": "code",
        "outputId": "8bc1aa11-1c52-433f-eb58-6e9647566186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x + y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxP8ZQ7wyxFI",
        "colab_type": "code",
        "outputId": "3d5f5a43-bbad-4d62-f70a-be6e45fe8c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x - y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1,  3,  2,  4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXkilc4Sy2ky",
        "colab_type": "code",
        "outputId": "bc25daa4-0b9f-4609-f4dc-fa0ca524d2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x * y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, -2,  3,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Jf93HazFl_",
        "colab_type": "code",
        "outputId": "7aee6180-9d8b-43bd-9706-4e414edb0416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x > y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_gNjDcMzINl",
        "colab_type": "code",
        "outputId": "ff32d5e1-d82b-4342-e4e0-f12cbef5d975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x == y\n",
        "z.get()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juu9yAzC0L0X",
        "colab_type": "text"
      },
      "source": [
        "### **Building an Encrypted Database**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbOg3ce-jqeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import torch as th"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtG02b20mjp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2index = {}\n",
        "index2char = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlvFPH1nmqC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,char in enumerate(' ' + string.ascii_lowercase + '0123456789' + string.punctuation):\n",
        "  char2index[char] = i\n",
        "  index2char[i] = char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "975Gzj2jn3eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  str_input = \"Hello\"\n",
        "  max_len = 8\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t69KE8u4m_QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2values(str_input, max_len=8):\n",
        "\n",
        "  str_input = str_input[:max_len].lower()\n",
        "  \n",
        "  if(len(str_input)<max_len):\n",
        "    str_input = str_input + \" , \" * (max_len-len(str_input))\n",
        "    \n",
        "  values = list()\n",
        "  for char in str_input:\n",
        "    values.append(char2index[char])\n",
        "    \n",
        "  return th.tensor(values).long()\n",
        "\n",
        "\n",
        "def values2string(input_values):\n",
        "  s = \"\"\n",
        "  for value in input_values:\n",
        "    s += int2char[int(value)]\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcMCDPFem_KQ",
        "colab_type": "code",
        "outputId": "84125973-8fee-4559-ba19-7755b689d898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string2values(str_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8,  5, 12, 12, 15,  0, 48,  0,  0, 48,  0,  0, 48,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_x5rsI7m_EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(index, length):\n",
        "  vect = th.zeros(length).long()\n",
        "  vect[index] = 1\n",
        "  return vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNvCec_Xm-mX",
        "colab_type": "code",
        "outputId": "3df78c23-eb75-47a1-e1ce-76b22371ec32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "one_hot(3,5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlusLUfYm-hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2one_hot_matrix(str_input, max_len=8):\n",
        "\n",
        "  str_input = str_input[:max_len].lower()\n",
        "  \n",
        "  if(len(str_input)<max_len):\n",
        "    str_input = str_input + \" , \" * (max_len-len(str_input))\n",
        "    \n",
        "  char_vectors = list()\n",
        "  for char in str_input:\n",
        "    char_v = one_hot(char2index[char], len(index2char)).unsqueeze(0)\n",
        "    char_vectors.append(char_v)\n",
        "    \n",
        "  return th.cat(char_vectors, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya4tflVdmpwS",
        "colab_type": "code",
        "outputId": "9f7ec11c-16b4-41ba-a42d-5929c5343a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "matrix = string2one_hot_matrix(\"Hello\")\n",
        "matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyFWASu4stWe",
        "colab_type": "text"
      },
      "source": [
        "We can check if two encrypted keys match by doing the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW0FKGc6qpt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str_a = string2one_hot_matrix(\"Helll\")\n",
        "str_b = string2one_hot_matrix(\"Hello\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S86s_BZ4qplO",
        "colab_type": "code",
        "outputId": "aa617afb-9793-49f9-b3ff-c7fe4d9a125f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# returns 1 when both strings are the same\n",
        "def strings_equal(str_a, str_b):\n",
        "\n",
        "  if len(str_a) == len(str_b):\n",
        "    vect = (str_a * str_b).sum(1)\n",
        "\n",
        "    x = vect[0]\n",
        "\n",
        "    for i in range(vect.shape[0]-1):\n",
        "      x = x * vect[i+1]\n",
        "  else:\n",
        "    x = th.tensor(0)\n",
        "\n",
        "  return x\n",
        "\n",
        "strings_equal(str_a,str_b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvLmBt5HMXW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0j0CMTiDAgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncryptedDB():\n",
        "  \n",
        "  def __init__(self, *owners, max_key_len=8,max_val_len=8):\n",
        "    self.max_key_len = max_key_len\n",
        "    self.max_val_len = max_val_len\n",
        "  \n",
        "    # We'll encode the keys with one_hot_matrix and the data with string2values.\n",
        "    self.keys = list()\n",
        "    self.values = list()\n",
        "    self.owners = owners\n",
        "\n",
        "    \n",
        "    \n",
        "  def add_entry(self, key, value):\n",
        "    key = string2one_hot_matrix(key)\n",
        "    key = key.share(*self.owners)\n",
        "    self.values.append(key)\n",
        "    \n",
        "    value = string2values(value, max_len=self.max_val_len)\n",
        "    value = value.share(*self.owners)\n",
        "    self.values.append(value)\n",
        "        \n",
        "    \n",
        "  \n",
        "  def query(self, query_str):\n",
        "    query_matrix = string2one_hot_matrix(query_str)\n",
        "    query_matrix = query_matrix.share(*self.owners)\n",
        "\n",
        "    key_matches = list()\n",
        "    \n",
        "    for key in self.keys:\n",
        "      \n",
        "      key_match = strings_equal(key, query_matrix)\n",
        "      key_matches.append(key_match)\n",
        "\n",
        "    result = self.values[0] * key_matches[0]\n",
        "\n",
        "    for i in range(len(self.values)-1):\n",
        "      result += self.values[i+1] + key_matches[i+1]\n",
        "      \n",
        "    result = result.get()\n",
        "\n",
        "    return values2string(result).replace(\".\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz1j5CM3IdIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhaGnGsNqpdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = EncryptedDB(bob,alice,secure_worker,max_val_len=256)\n",
        "\n",
        "db.add_entry(\"key1\", \"value1\")\n",
        "db.add_entry(\"key2\", \"value2\")\n",
        "db.add_entry(\"key3\", \"value3\")\n",
        "db.add_entry(\"key4\", \"value4\")\n",
        "\n",
        "db.query(\"key1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnkbJlwK1H41",
        "colab_type": "text"
      },
      "source": [
        "### **Encrypted Deep Learning in PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyAmxzYG1UQV",
        "colab_type": "text"
      },
      "source": [
        "First we'll train a regular model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyn5dkXZzK_f",
        "colab_type": "code",
        "outputId": "926a305c-463e-466d-c437-2f2e84d5ce80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Toy dataset\n",
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = th.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(2,20)\n",
        "    self.fc2 = nn.Linear(20,1)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "  \n",
        "model =  Net()\n",
        "\n",
        "def train():\n",
        "  \n",
        "  opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
        "  for i in range(20):\n",
        "    \n",
        "    opt.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = ((pred-target)**2).sum()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print(loss.data)\n",
        "    \n",
        "    \n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5224)\n",
            "tensor(5.4030)\n",
            "tensor(19.5920)\n",
            "tensor(3.5385)\n",
            "tensor(0.9767)\n",
            "tensor(0.8976)\n",
            "tensor(0.8505)\n",
            "tensor(0.7986)\n",
            "tensor(0.7350)\n",
            "tensor(0.6619)\n",
            "tensor(0.5810)\n",
            "tensor(0.4948)\n",
            "tensor(0.4105)\n",
            "tensor(0.3396)\n",
            "tensor(0.2667)\n",
            "tensor(0.2072)\n",
            "tensor(0.1620)\n",
            "tensor(0.1242)\n",
            "tensor(0.0963)\n",
            "tensor(0.0758)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdUPFwwZ3CLy",
        "colab_type": "code",
        "outputId": "444b1428-7005-4f75-c337-deaf6b20a38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model(data)\n",
        "# it's suposed to predict 0,0,1,1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1787],\n",
              "        [-0.0091],\n",
              "        [ 0.9044],\n",
              "        [ 0.8731]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbN2t1je3pQ5",
        "colab_type": "text"
      },
      "source": [
        "Now, we'll encrypt both model and data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5wh5MKL3czP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_model = model.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm0SMv7v38fj",
        "colab_type": "code",
        "outputId": "5c35dca3-463f-498e-8edf-99a1bdb99160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#just checking that it is indeed encrypted\n",
        "list(encrypted_model.parameters())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:61526291620 -> alice:99966357011]\n",
              " \t-> (Wrapper)>[PointerTensor | me:91775101613 -> bob:99043759602]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:81270836623 -> alice:70833606441]\n",
              " \t-> (Wrapper)>[PointerTensor | me:15704866925 -> bob:84054783600]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:89406463235 -> alice:11130594071]\n",
              " \t-> (Wrapper)>[PointerTensor | me:73475118996 -> bob:74594146332]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              " \t-> (Wrapper)>[PointerTensor | me:71261363168 -> alice:38937786591]\n",
              " \t-> (Wrapper)>[PointerTensor | me:21461818858 -> bob:93208156546]\n",
              " \t*crypto provider: secure_worker*]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ2e1O424CyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_data = data.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGCzcQR44jPA",
        "colab_type": "code",
        "outputId": "47f5cf7f-4fd7-4189-8d66-d5abc5b4a9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "encrypted_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:30947426895 -> alice:92302330790]\n",
              "\t-> (Wrapper)>[PointerTensor | me:79820632789 -> bob:9951067081]\n",
              "\t*crypto provider: secure_worker*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxaTf7Jj4lIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_prediction = encrypted_model(encrypted_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOG9HL_54skI",
        "colab_type": "code",
        "outputId": "1e728075-35d9-409e-e5be-e00f25435847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "encrypted_prediction.get().float_precision()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1800],\n",
              "        [-0.0080],\n",
              "        [ 0.9050],\n",
              "        [ 0.8730]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXFczX5S6Hrj",
        "colab_type": "text"
      },
      "source": [
        "### **Encrypted Deep Learning in Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_fL5j2G6Mv3",
        "colab_type": "text"
      },
      "source": [
        "Now we'll reproduce the previous section in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yGHKdBy41bs",
        "colab_type": "code",
        "outputId": "eeae2629-f30a-4685-f188-553b3efc547e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3,3), input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer=keras.optimizers.Adadelta(),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size = batch_size,\n",
        "          epochs=epochs, verbose=1, validation_data=(x_test,y_test))\n",
        "score = model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test loss', score[0])\n",
        "print('Test accuracy', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0628 14:20:18.470101 140035515029376 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 2.3030 - acc: 0.1044 - val_loss: 2.3024 - val_acc: 0.1038\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 2.3015 - acc: 0.1095 - val_loss: 2.3009 - val_acc: 0.1116\n",
            "Test loss 2.30091893081665\n",
            "Test accuracy 0.1116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OLGm-P49pQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('short-conv-mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0agHKlnvdnWB",
        "colab_type": "text"
      },
      "source": [
        "This time we'll do a keras hook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMsm-DfVdixH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Flatten, ReLU, Activation\n",
        "\n",
        "import syft as sy\n",
        "hook = sy.KerasHook(tf.keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfa6ARGweL6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "num_classes = 10\n",
        "input_shape = (1,28,28,1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3,3), batch_input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(AveragePooling2D((2,2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "# loading pre-trained weights\n",
        "pre_trained_weights = 'short-conv-mnist.h5'\n",
        "model.load_weights(pre_trained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT3gUdwQe5do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = True\n",
        "\n",
        "alice = sy.TFEWorker(host='localhost:4000', auto_managed=AUTO)\n",
        "bob = sy.TFEWorker(host='localhost:4001', auto_managed=AUTO)\n",
        "carol = sy.TFEWorker(host='localhost:4002', auto_managed=AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgO8ix2Ag-tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.share(alice, bob, carol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXOsx5mRhBwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.serve(num_requests=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phD145e0iVWr",
        "colab_type": "text"
      },
      "source": [
        "And that should be enough to start our server. If you want to check how the clients work, go to *https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/* and click on Part13 to follow the full tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiL6IdlkhJnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}